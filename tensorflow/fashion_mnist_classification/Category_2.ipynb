{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Category_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bYGVY1KwFrQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "1c9a4242-fe42-470b-a32a-53239493a2e8"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "def solution_model():\n",
        "\n",
        "  fashion_mnist = tf.keras.datasets.fashion_mnist\n",
        "\n",
        "  (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "  X_train, X_test = X_train / 255.0 , X_test / 255.0\n",
        "\n",
        "  model = tf.keras.Sequential([\n",
        "       tf.keras.layers.Flatten(input_shape=(28,28)),\n",
        "       tf.keras.layers.Dense(512, activation='relu'),\n",
        "       tf.keras.layers.Dense(10, activation='softmax')                          \n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "  model.fit(X_train, y_train, epochs=10, verbose=1)\n",
        "\n",
        "  # YOUR CODE HERE\n",
        "  return model\n",
        "\n",
        "\n",
        "# Note that you'll need to save your model as a .h5 like this.\n",
        "# When you press the Submit and Test button, your saved .h5 model will\n",
        "# be sent to the testing infrastructure for scoring\n",
        "# and the score will be returned to you.\n",
        "if __name__ == '__main__':\n",
        "    model = solution_model()\n",
        "    model.save(\"mymodel.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.4757 - accuracy: 0.8307\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3602 - accuracy: 0.8682\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3208 - accuracy: 0.8810\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2980 - accuracy: 0.8890\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2797 - accuracy: 0.8971\n",
            "Epoch 6/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2653 - accuracy: 0.9012\n",
            "Epoch 7/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2535 - accuracy: 0.9053\n",
            "Epoch 8/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2408 - accuracy: 0.9100\n",
            "Epoch 9/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2320 - accuracy: 0.9127\n",
            "Epoch 10/10\n",
            "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2230 - accuracy: 0.9165\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}